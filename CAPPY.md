# Project Brief

## Requirements
- A valid REDCap API token for the project with PID 34345 is required to enable SecureChatAI features.


## What this is
- **Cappy Code**: PHI-safe agentic code runner CLI (like Claude Code, but using SecureChatAI)
- Local "hands" that execute tools, with SecureChatAI as the "brain"
- Safe file operations with full audit logging
- Works in any project folder - looks for `CAPPY.md` (project context) and `.cappyignore`

## Tech stack
- Backend: Python 3.10+ CLI
- Dependencies: pyyaml, python-dotenv, requests
- Build/tooling: pip, pyproject.toml (installable package)
- Local dev: `pip install -e .` then `cappy chat` from anywhere

## Installation (New User Setup)
```bash
# 1. Clone or copy the repo
cd path/to/cappy_code

# 2. Install Python dependencies
pip3 install -e .

# 3. Set up SecureChatAI credentials
cp .env.example .env
# Edit .env and add your REDCAP_API_URL and REDCAP_API_TOKEN

# 4. Find your Python bin directory
which python3  # e.g., /Library/Frameworks/Python.framework/Versions/3.13/bin/python3

# 5. Add Python bin to PATH (for permanent access from any directory)
# Extract the directory path from step 4, then add to ~/.zshrc (macOS) or ~/.bashrc (Linux):
echo 'export PATH="/path/to/your/python/bin:$PATH"' >> ~/.zshrc
source ~/.zshrc

# 6. Verify installation
cappy chat  # Should work from any directory now
```

**Requirements:**
- Python 3.10+
- `patch` command (usually pre-installed on macOS/Linux)
- SecureChatAI API credentials (REDCAP_API_URL, REDCAP_API_TOKEN)

## Repo layout
```
cappy_code/
‚îú‚îÄ‚îÄ .env                  # SecureChatAI credentials (REDCAP_API_URL, REDCAP_API_TOKEN)
‚îú‚îÄ‚îÄ .env.example          # Template for credentials
‚îú‚îÄ‚îÄ cappy_config.yaml     # Config (default_model, allowed_models, safety limits)
‚îú‚îÄ‚îÄ pyproject.toml        # Package config, entry point for `cappy` command
‚îú‚îÄ‚îÄ requirements.txt      # Dependencies
‚îú‚îÄ‚îÄ logs/                 # Audit logs (JSON lines, auto-created)
‚îú‚îÄ‚îÄ AGENT.md              # Usage documentation
‚îú‚îÄ‚îÄ CLAUDE.md             # This file
‚îî‚îÄ‚îÄ cappy/
    ‚îú‚îÄ‚îÄ __init__.py       # v0.1.0
    ‚îú‚îÄ‚îÄ cli.py            # Entry point, argparse commands
    ‚îú‚îÄ‚îÄ tools.py          # Tool implementations (scan, search, read, write, edit, apply, run)
    ‚îú‚îÄ‚îÄ config.py         # YAML config loader
    ‚îú‚îÄ‚îÄ logger.py         # JSON lines audit logging
    ‚îú‚îÄ‚îÄ ai_client.py      # SecureChatAI HTTP client (REDCap External Module API)
    ‚îú‚îÄ‚îÄ agent.py          # Agentic loop orchestrator + system prompt
    ‚îî‚îÄ‚îÄ chat.py           # Interactive chat REPL
```

## Current state
### Working / shipped
- **Interactive chat**: `cappy chat` - Claude Code-like experience
- **Agentic loop**: `cappy agent "task"` - single task execution
- **8 tools**: scan, search, read, write, **edit** (NEW!), apply, run (+ agent/chat commands)
- **JSON schema enforcement**: Structured output for reliable tool calling (Jan 2026)
- **SecureChatAI integration**: HTTP client via REDCap External Module API
- **Schema-capable models only**: gpt-4.1, gpt-5, o1, o3-mini, llama3370b (reliable agentic work)
- **Project context**: Loads `CAPPY.md` from cwd into system prompt
- **Ignore patterns**: Respects `.cappyignore` in scan/search
- **Multi-line paste**: `/paste` command for pasting error blocks
- **Audit logging**: All tool calls logged to `./logs/` as JSON lines
- **Safety limits**: max_files_touched_per_run, no overwrite without flag
- **Permanent CLI access**: `cappy` command works from any directory (PATH in ~/.zshrc)

### Known issues
- Requires `patch` command on system PATH for apply tool

## Recent Major Changes (Jan 8, 2026)

### üéØ JSON Schema Enforcement
- **Problem**: Inconsistent tool calling - models would forget to use tools, output malformed JSON args, or miss completion signals
- **Solution**: Added `json_schema` parameter to SecureChatAI API calls with strict output structure
- **Impact**: Agent responses now reliably follow format: `{"action": "tool_call"|"done", "tool_name": "...", "tool_args": {...}, "message": "..."}`
- **Files changed**: `cappy/ai_client.py`, `cappy/agent.py`, `cappy/chat.py`

### üîß New Edit Tool
- **Problem**: File editing was error-prone (read entire file ‚Üí reconstruct ‚Üí overwrite)
- **Solution**: Added surgical `edit(filepath, old_string, new_string)` tool like Claude Code
- **Safety**: Validates old_string exists and is unique before replacing
- **Impact**: Way more reliable edits, less token usage, clearer error messages
- **Files changed**: `cappy/tools.py`, `cappy/agent.py`

### üé® Schema-Capable Models Only
- **Problem**: SecureChatAI EM only supports json_schema for specific models (gpt-4.1, o1, o3-mini, llama3370b)
- **Solution**: Restricted `AGENTIC_MODELS` to schema-capable models only
- **Trade-off**: Lost gpt-4o, claude, deepseek for agentic work (still available for chat-only)
- **Impact**: More reliable tool calling, consistent behavior across models
- **Files changed**: `cappy/ai_client.py`, `cappy_config.yaml`

### üöÄ Permanent CLI Installation
- **Problem**: `cappy` command only worked in terminal sessions where PATH was set
- **Solution**: Added Python bin directory to `~/.zshrc` permanently
- **Impact**: `cappy chat` now works from any directory, survives reboots
- **Command**: `export PATH="/Library/Frameworks/Python.framework/Versions/3.13/bin:$PATH"`

## Roadmap / TODO
- Plan approval workflow (require_plan=true enforcement)
- verify_command auto-run after apply
- Streaming responses
- Better error recovery in agentic loop
- Expand Cappy‚Äôs HTTP/network tools (whitelisted endpoints, controlled payloads)
- Consider ephemeral image/OCR tool for reading screenshots without permanent storage

## Chat commands
```
/help     - Show help
/paste    - Multi-line input mode (end with EOF)
/clear    - Clear conversation history
/model    - Show current model
/model o1 - Switch model
/quit     - Exit
```

## Available models (for agentic work)
**Schema-capable models only** (for reliable structured output):
- gpt-4.1 (strong coding, good default)
- gpt-5 (latest OpenAI, schema support TBD)
- o1 (deep reasoning - current default)
- o3-mini (reasoning, faster)
- llama3370b (LLaMA with schema support)

**Non-agentic models** (chat only, no schema support):
- gpt-4o, claude, deepseek, gemini25pro, gemini20flash, llama-Maverick

## Guardrails (important)
- Make small, reviewable diffs (avoid sweeping refactors unless asked)
- Do not rename files/folders unless explicitly requested
- Do not touch CI/CD, deployment, or infra files unless explicitly requested
- Do not introduce new libraries unless asked
- Prefer existing patterns and utilities already in the repo
- When changing behavior, update or add tests if tests exist

## Claude Rules (Repo Safety)
- Never commit, merge, or push to `main` (or `master`).
- Work must occur on a `cc/YYYY-MM-DD-topic` branch.
- You may commit on the session branch.
- Before any changes: show `git status`. If dirty, stop.
- Do not run `gcloud`, `terraform`, `kubectl`, `aws` unless explicitly told.
- Avoid drive-by refactors. Only change code related to the asked task.
- If you add/modify an API contract, you must update:
  - the contract schema/types
  - at least one example payload
  - tests that validate the contract


## How to verify changes
When you say ‚Äútested‚Äù, include:
- The exact command(s) run
- Pass/fail result (exit code)
- Any relevant output summary

## Communication style
- If a change is large, propose a plan first (no code) and wait for approval
- Call out any risky/destructive operations before doing them
- Keep changes scoped to the requested feature

